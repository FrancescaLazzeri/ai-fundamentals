{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36564bitbaseconda6d689ab686ce4afc84d90c7a8e34c48d",
   "display_name": "Python 3.6.5 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "Natural Language Processing (NLP) is a branch of artificial intelligence (AI) that deals with written and spoken language. You can use NLP to build solutions that extracting semantic meaning from text or speech, or that formulate meaningful responses in natural language.\n",
    "\n",
    "## Using the Text Analytics Cognitive Service\n",
    "\n",
    "Microsoft Azure *cognitive services* includes the *Text Analytics* service, which provides some out-of-the-box NLP capabilities, including the identification of key phrases in text, and the classification of text based on sentiment.\n",
    "\n",
    "For example, suppose Adventure Works Cycles encourages customers to submit reviews for its cycle rental service. You could use the Text Analytics service to summarize the reviews by extracting key phrases, and determine which reviews are positive, and which are negative.\n",
    "\n",
    "If you don't already have one, use the following steps to create a **Cognitive Services** resource in your Azure subscription:\n",
    "\n",
    "1. In another browser tab, open the Azure portal (<a href='https://portal.azure.com' target='_blank'>https://portal.azure.com</a>), signing in with your Microsoft account.\n",
    "2. Click the **&#65291;Create a resource** button, search for *Cognitive Services*, and create a **Cognitive Services** resource with the following settings:\n",
    "    - **Name**: *Enter a unique name*.\n",
    "    - **Subscription**: *Your Azure subscription*.\n",
    "    - **Location**: *Any available location*.\n",
    "    - **Pricing tier**: S0\n",
    "    - **Resource group**: *Create a resource group with a unique name*.\n",
    "3. Wait for deployment to complete. Then go to your cognitive services resource, and on the **Quick start** page, note the keys and endpoint. You will need these to connect to your cognitive services resource from client applications.\n",
    "\n",
    "To use your cognitive services resource, client applications need its  endpoint and authentication key:\n",
    "\n",
    "1. Copy the **Key1** for your resource and paste it in the code below, replacing **YOUR_COG_KEY**.\n",
    "2. Copy the **endpoint** for your resource and and paste it in the code below, replacing **YOUR_COG_ENDPOINT**.\n",
    "3. Run the code in the cell below by clicking its green <span style=\"color:green\">&#9655</span> button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scripts import reviews_analysis\n",
    "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "# Set API configuration\n",
    "cog_key = 'YOUR_COG_KEY'\n",
    "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
    "\n",
    "# Get a client for your text analytics cognitive service resource\n",
    "text_analytics_client = TextAnalyticsClient(endpoint=cog_endpoint,\n",
    "                                            credentials=CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# Read the reviews in the /data/reviews folder\n",
    "reviews_folder = os.path.join('data', 'reviews')\n",
    "reviews = []\n",
    "for file_name in os.listdir(reviews_folder):\n",
    "    review_text = open(os.path.join(reviews_folder, file_name)).read()\n",
    "    review = {\"id\": file_name, \"language\": \"en\", \"text\": review_text}\n",
    "    reviews.append(review)\n",
    "\n",
    "# Analyze the reviews\n",
    "reviews_analysis.analyze_reviews(text_analytics_client, reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "> **Note**: If you're curious about the code used to retrieve the key phrases and sentiment scores from the Text Analytics Service, look at the **reviews_analaysis.py** file in the **scripts** folder."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using the Language Understanding Intelligence Service\n",
    "\n",
    "Increasingly, we expect computers to be able to use AI in order to understand spoken or typed commands in natural language. For example, Adventure Works Cycles might want to implement office automation that enables employees to control the office environment using voice commands such as \"switch on the light\" or \"put the fan on\", and have an AI-powered device understand the command and take appropriate action.\n",
    "\n",
    "### Create a LUIS Authoring Resource\n",
    "\n",
    "The Microsoft cognitive services include the Language Understanding Intelligence Service (LUIS), which enables you to define *intents* that are applied to *entities* based on *utterances*. You can use your Cognitive Services resource to *publish* a LUIS app, but you must create a separate resource for *authoring* the app.\n",
    "\n",
    "1. In another browser tab, open the Azure portal (<a href='https://portal.azure.com' target='_blank'>https://portal.azure.com</a>), signing in with your Microsoft account.\n",
    "2. Click **+ Create a resource**, and search for *Language Understanding*.\n",
    "3. In the list of services, click **Language Understanding**.\n",
    "4. In the **Language Understanding** blade, click **Create**.\n",
    "5. In the **Create** blade, select only **Authoring**. Then enter the following details and click **Create**\n",
    "  * **Name**: A unique name for your service\n",
    "  * **Subscription**: Your Azure subscription\n",
    "  * **Resource Group**: The existing resource group you used previously\n",
    "  * **Authoring location**: Any available location\n",
    "  * **Authoring pricing tier**: F0\n",
    "6. Wait for the service to be created.\n",
    "\n",
    "### Create a LUIS App\n",
    "\n",
    "To implement natural language understanding with LUIS, you create an app; and then add entities, intents, and utterances to define the commands you want the app to understand:\n",
    "\n",
    "1. Open a new browser tab and navigate to the LUIS portal at <a href='https://preview.luis.ai/' target='_blank'>https://preview.luis.ai/</a>.\n",
    "2. Sign in using the Microsoft account associated with your Azure subscription.\n",
    "3. If this is the first time you have signed into LUIS, you may need to grant the app some permissions to access your account details. Then complete the *Welcome* steps by selecting the existing LUIS authoring resource you just created in your Azure subscription. \n",
    "4. Open the **My Apps** page, and select your subscription and LUIS authoring resource. Then click **Create** and create a new app with the following settings:\n",
    "  - **Name**: Office Automation\n",
    "  - **Culture**: English\n",
    "  - **Description**: Adventure Works office automation\n",
    "  - **Prediction resource**: *Your cognitive services resource*\n",
    "5. If a panel with tips for creating an effective LUIS app is displayed, close it.\n",
    "\n",
    "### Create an Entity\n",
    "\n",
    "An *entity* is a thing that your language model can identify and do something with. In this case, your LUIS app will be used to control various *devices* in the office, such as lights or fans; so you'll create a *device* entity that includes a list of the types of device that you want the app to work with. For each device type, you'll create a sublist that identifies the name of the device (for example *light*) and any synonyms that might be used to refer to this type of device (for example *lamp*).\n",
    "\n",
    "1. In the LUIS page for your app, in the pane on the left, click **Entities**. Then click **Create new entity**, and create a new entity named **device** of type **List** and click **Next**.\n",
    "2. In the **Create a list entity** page, click *Add new sublist* and type **light**, then press ENTER.\n",
    "3. After the **light** entity has been added, under **Synonyms**, click *Type in value*, and type **lamp** and press ENTER.\n",
    "4. Add a second sublist named **fan** with the synonym **AC**.\n",
    "5. Click **Create** to create the **device** entity with its **light** and **fan** sublists.\n",
    "\n",
    "### Create Intents\n",
    "\n",
    "An *intent* is an action you want to perform on one or more entities - for example, you might want to switch a light on, or turn a fan off. In this case, you'll define two intents: one to switch a device on, and another to switch a device off. For each intent, you'll specify sample *utterances* that indicate the kind of language used to indicate the intent.\n",
    "\n",
    "1. In the pane on the left, click **Intents**. Then click **Create new intent**, and add an intent with the name **Switch On**.\n",
    "2. In the **Utterances** page for the **Switch On** intent, type ***turn the light on*** and press **Enter** to add this utterance to the list.\n",
    "3. In the list of utterances, in the *turn the light on* utterance, click the word \"light\", and assign it to the **device** entity.\n",
    "4. Add a second utterance to the **Switch On** intent, with the phrase ***turn the fan on***. Then assign the word \"fan\" to the **device** entity.\n",
    "5. In the pane on the left, click **Intents** and click **Create new intent**, to add a second intent with the name **Switch Off**.\n",
    "6. In the **Utterances** page for the **Switch Off** intent, add the utterance ***turn the light off*** and assign the word \"light\" to the **device** entity.\n",
    "7. Add a second utterance to the **Switch Off** intent, with the phrase ***turn the fan off***. Then connect the word \"fan\" to the **device** entity.\n",
    "\n",
    "### Train and Test the Language Model\n",
    "\n",
    "Now you're ready to use the data you've provided in the form of entities, intents, and uterances to train the language model for your LUIS app.\n",
    "\n",
    "1. At the top of the LUIS page for your app, click **Train** to train the language model\n",
    "2. After the app has been trained, click **Test**, and then in the test pane, enter the following utterances and inspect the results to verify that they are correctly interpreted as commands for the *Switch On* and *Switch Off* intents with the appropriate entities:\n",
    "    * *turn on the light*\n",
    "    * *switch the light off*\n",
    "    * *switch the fan on*\n",
    "    * *turn off the fan*\n",
    "    \n",
    "### Publish the Model and Configure Endpoints\n",
    "\n",
    "To use your trained model in a client application, you must publish it as an endpoint to which the client applications can send new utterances; from which intents and entitites will be predicted.\n",
    "\n",
    "1. At the top of the LUIS page for your app, click **Publish**. Then select **Production slot** and click **Done**.\n",
    "2. After the model has been published, at the top of the LUIS page for your app, click **Manage**. Then on the **Application Information** tab, note the **Application ID** for your app. Copy this and paste it in the code below to replace **YOUR_LUIS_APP_ID**.\n",
    "3. On the **Azure Resources** tab, note the **Primary key** and **Endpoint URL** for your language model, which is based on your cognitive services resource. Copy these and paste them into the code below, replacing **YOUR_COG_KEY** and **YOUR_COG_ENDPOINT**.\n",
    "4. Run the cell below, and when prompted (at the top of this page), enter the text *turn the light on*. The text is interpreted by your LUIS model and an appropriate image is displayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import office_auto\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    # Set up API configuration\n",
    "    luis_app_id = 'YOUR_LUIS_APP_ID'\n",
    "    cog_key = 'YOUR_COG_KEY'\n",
    "    cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
    "\n",
    "    # prompt for a command\n",
    "    command = input('Please enter a command: \\n')\n",
    "\n",
    "    # get the predicted intent and entity\n",
    "    img_name = office_auto.get_intent(luis_app_id, cog_key, cog_endpoint, command)\n",
    "\n",
    "    # display an appropriate image\n",
    "    img = Image.open(os.path.join(\"data\", \"office-auto\" ,img_name))\n",
    "    plt.axis('off')\n",
    "    plt. imshow(img)\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Re-run the cell above, trying the following phrases:\n",
    "\n",
    "* *turn on the light*\n",
    "* *put the lamp off*\n",
    "* *switch the fan on*\n",
    "* *switch the light on*\n",
    "* *switch off the light*\n",
    "* *turn off the fan*\n",
    "* *switch the AC on*\n",
    "\n",
    "> **Note**: If you're curious about the code used to retrieve the intents and entitites from your LUIS app, look at the **office_auto.py** file in the **scripts** folder."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using the Speech Cognitive Service\n",
    "\n",
    "So far, we've seen how analyze text; but increasingly AI systems enable humans to communicate with software services through speech recognition. To support this, the **Speech** cognitive service provides a simple way to transcribe spoken language into text.\n",
    "\n",
    "In the cell below, paste the LUIS Application ID, Cognitive Services key, and Cognitive Services endpoint you've used previously. Then run the cell.\n",
    "\n",
    "This code will use the Speech cognitive service to transcribe the **light-on.wav** audio file, and then use LUIS to determine the intent of the transcribed speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import office_auto\n",
    "import os\n",
    "import IPython\n",
    "import os\n",
    "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
    "\n",
    "try:\n",
    "    # Set up API configuration\n",
    "    luis_app_id = 'YOUR_LUIS_APP_ID'\n",
    "    cog_key = 'YOUR_COG_KEY'\n",
    "    cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
    "    \n",
    "    # Get region from endpoint\n",
    "    cog_region = cog_endpoint[8:cog_endpoint.find('.')]\n",
    "\n",
    "    # Get spoken command\n",
    "    file_name = 'light-on.wav'\n",
    "    audio_file = os.path.join('data', 'office-auto', file_name)\n",
    "\n",
    "    # Configure speech recognizer\n",
    "    speech_config = SpeechConfig(cog_key, cog_region)\n",
    "    audio_config = AudioConfig(filename=audio_file) #Use file instead of default (microphone)\n",
    "    speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
    "\n",
    "    # Use a one-time, synchronous call to transcribe the speech\n",
    "    speech = speech_recognizer.recognize_once()\n",
    "\n",
    "    # get the predicted intent and entity\n",
    "    img_name = office_auto.get_intent(luis_app_id, cog_key, cog_endpoint, speech.text)\n",
    "\n",
    "    # Play audio and display image\n",
    "    IPython.display.display(IPython.display.Audio(audio_file, autoplay=True),\n",
    "                            IPython.display.Image(data=os.path.join(\"data\", \"office-auto\" ,img_name)))\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Try modifying the cell above to use the **light-off.wav** audio file."
   ]
  }
 ]
}